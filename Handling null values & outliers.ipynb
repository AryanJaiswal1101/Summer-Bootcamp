{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Handling Null Values and Outliers in Python\n",
    "\n",
    "- Introduction\n",
    "\n",
    "Data cleaning is a critical step in the data preprocessing workflow. It ensures that the dataset is free from inconsistencies, inaccuracies, and unwanted noise, thereby improving the quality of the data. Handling null values and outliers is an essential part of this process.\n",
    "\n",
    "- Null Values\n",
    "\n",
    "Null values, or missing values, occur when no data value is stored for a variable in an observation. These can result from various reasons such as data entry errors, missing data during collection, or data corruption. Handling null values appropriately is crucial because they can lead to biased estimates, reduced statistical power, and misleading conclusions.\n",
    "\n",
    "- Outliers\n",
    "\n",
    "Outliers are data points that differ significantly from other observations. They can occur due to variability in the data, measurement errors, or experimental errors. Outliers can distort statistical analyses and models, leading to inaccurate results. Identifying and handling outliers helps improve the robustness and accuracy of the data analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Handling Null Values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Identifying Null Values\n",
    "\n",
    "The first step in handling null values is identifying where they exist in the dataset. In Pandas, this can be done using the isnull() and sum() functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load example dataset\n",
    "data = pd.DataFrame({\n",
    "    'A': [1, 2, None, 4, 5],\n",
    "    'B': [None, 2, 3, None, 5],\n",
    "    'C': [1, None, None, 4, None]\n",
    "})\n",
    "\n",
    "# Identify null values\n",
    "null_values = data.isnull()\n",
    "print(null_values)\n",
    "\n",
    "# Count null values in each column\n",
    "null_counts = data.isnull().sum()\n",
    "print(null_counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Removing Null Values\n",
    "\n",
    "Sometimes, it might be appropriate to remove rows or columns with null values, especially if the missing data is minimal. Removing null values can be done using the dropna() method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove rows with any null values\n",
    "data_dropped_rows = data.dropna()\n",
    "print(data_dropped_rows)\n",
    "\n",
    "# Remove columns with any null values\n",
    "data_dropped_cols = data.dropna(axis=1)\n",
    "print(data_dropped_cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Imputing Null Values\n",
    "\n",
    "Another approach is to impute null values with a specific value, such as the mean, median, or a constant. This method is useful when the amount of missing data is not too large and the values can be reasonably estimated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Sample data with null values\n",
    "data = {'Age': [25, None, 30, None], 'Income': [50000, 60000, None, 75000]}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Impute missing values in 'Age' with the mean\n",
    "df['Age'] = df['Age'].fillna(df['Age'].mean())\n",
    "\n",
    "# Impute missing values in 'Income' with 0\n",
    "df['Income'] = df['Income'].fillna(0)\n",
    "\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Impute null values with the mean of the column\n",
    "data_imputed_mean = data.fillna(data.mean())\n",
    "print(data_imputed_mean)\n",
    "\n",
    "# Impute null values with a constant value\n",
    "data_imputed_constant = data.fillna(0)\n",
    "print(data_imputed_constant)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Handling Outliers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Identifying Outliers\n",
    "\n",
    "Outliers can be identified using statistical methods or visualization techniques like box plots. A box plot is a standardized way of displaying the distribution of data based on a five-number summary (minimum, first quartile, median, third quartile, and maximum)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Sample data\n",
    "data = {'price': [10, 15, 20, 500, 25]}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Calculate quartiles\n",
    "Q1 = df['price'].quantile(0.25)\n",
    "Q3 = df['price'].quantile(0.75)\n",
    "\n",
    "# Calculate IQR\n",
    "IQR = Q3 - Q1\n",
    "\n",
    "# Lower and upper bounds\n",
    "lower_bound = Q1 - 1.5 * IQR\n",
    "upper_bound = Q3 + 1.5 * IQR\n",
    "\n",
    "# Find potential outliers\n",
    "outliers = df[(df['price'] < lower_bound) | (df['price'] > upper_bound)]\n",
    "\n",
    "print(outliers)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Removing Outliers\n",
    "\n",
    "Outliers can be removed based on a threshold value, such as the Interquartile Range (IQR) method. The IQR is a measure of statistical dispersion and is used to identify and remove outliers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove outliers using IQR method\n",
    "Q1 = data.quantile(0.25)\n",
    "Q3 = data.quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "\n",
    "data_no_outliers = data[~((data < (Q1 - 1.5 * IQR)) | (data > (Q3 + 1.5 * IQR))).any(axis=1)]\n",
    "print(data_no_outliers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Transforming Data to Reduce Outliers\n",
    "\n",
    "Transforming data can also help reduce the impact of outliers. Common transformations include logarithmic, square root, and cube root transformations. These transformations can make the data more normal-like and reduce the influence of outliers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Sample data with outliers\n",
    "data = {'income': [25000, 30000, 40000, 100000, 50000]}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Log transformation (assuming positive skew)\n",
    "df_log = df[['income']].apply(np.log)\n",
    "\n",
    "# Analyze and compare the distributions (histograms, boxplots)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Questions and Answers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q1. Identify and count the null values in the following DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data = pd.DataFrame({\n",
    "    'X': [1, None, 3, 4, 5],\n",
    "    'Y': [None, 2, 3, None, 5],\n",
    "    'Z': [1, 2, None, 4, None]\n",
    "})\n",
    "\n",
    "# Identify null values\n",
    "null_values = data.isnull()\n",
    "print(null_values)\n",
    "\n",
    "# Count null values in each column\n",
    "null_counts = data.isnull().sum()\n",
    "print(null_counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q2. Remove rows with any null values from the DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove rows with any null values\n",
    "data_dropped_rows = data.dropna()\n",
    "print(data_dropped_rows)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q3. Impute null values in the DataFrame with the mean of the respective columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Impute null values with the mean of the column\n",
    "data_imputed_mean = data.fillna(data.mean())\n",
    "print(data_imputed_mean)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q4. Identify outliers in the column 'X' using a box plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Visualize outliers using box plot\n",
    "plt.boxplot(data['X'].dropna())\n",
    "plt.title('Box plot of X')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q5. Remove outliers from the DataFrame using the IQR method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove outliers using IQR method\n",
    "Q1 = data.quantile(0.25)\n",
    "Q3 = data.quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "\n",
    "data_no_outliers = data[~((data < (Q1 - 1.5 * IQR)) | (data > (Q3 + 1.5 * IQR))).any(axis=1)]\n",
    "print(data_no_outliers)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
